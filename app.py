import streamlit as st
import importlib
import sys
import os
import re
import json
from langchain_neo4j import Neo4jGraph
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

DEBUG_MODE = True # Trueë¡œ ì„¤ì •í•˜ë©´ ìƒì„¸ ë¡œê·¸ ì¶œë ¥

def log_debug(message: str):
    """ë””ë²„ê·¸ ëª¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if DEBUG_MODE:
        print(f"ğŸ› DEBUG: {message}")

scripts_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "scripts")
if scripts_path not in sys.path:
    sys.path.append(scripts_path)

try:
    tutor_module = importlib.import_module("06_tutor_rag")
    process_turn = tutor_module.process_turn
    get_initial_state = tutor_module.get_initial_state
except ImportError as e:
    st.error(f"íŠœí„° ë¡œì§ ìŠ¤í¬ë¦½íŠ¸(06_tutor_rag.py)ë¥¼ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="AI ìˆ˜í•™ íŠœí„°", page_icon="ğŸ“š",
    layout="wide", initial_sidebar_state="expanded"
)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ“Š ë‚˜ì˜ í•™ìŠµ í˜„í™©")
    
    if "conversation_state" not in st.session_state:
        st.session_state.conversation_state = get_initial_state()

    current_state = st.session_state.conversation_state
    mastered_concepts_set = current_state.get("explained_concepts", set())
    explanation_counts = current_state.get("explanation_count", {})
    
    st.metric("ğŸ“ í•™ìŠµ ì™„ë£Œ ê°œë…", f"{len(mastered_concepts_set)} ê°œ")
    
    weak_concepts_list = [name for name, count in explanation_counts.items() if count >= 2]
    
    st.subheader("ğŸ¯ ë³µìŠµ ì¶”ì²œ ê°œë…")
    if weak_concepts_list:
        for concept in weak_concepts_list:
            st.warning(f"- {concept} (ì„¤ëª… {explanation_counts.get(concept, 0)}íšŒ)")
    else:
        st.success("ğŸ‰ ëª¨ë“  ê°œë…ì„ ì˜ ì´í•´í•˜ê³  ìˆì–´ìš”!")
        
    st.divider()
    
    if st.button("ğŸ”„ í•™ìŠµ ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.conversation_state = get_initial_state()
        st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í•™ìŠµ ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."}]
        st.rerun()

# ë©”ì¸ í™”ë©´
st.title("ğŸ“š ìˆ˜í¬ìë¥¼ ìœ„í•œ AI ìˆ˜í•™ íŠœí„°")
st.caption("ê°œë…ì˜ ì„ ìˆ˜ ì§€ì‹ì„ í™•ì¸í•˜ë©° ì°¨ê·¼ì°¨ê·¼ í•™ìŠµí•´ìš”!")

# ì±„íŒ… ê¸°ëŠ¥ í•µì‹¬ ë¡œì§

# 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ìˆ˜í•™ ê°œë…ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."}]


# 2. (í•µì‹¬) ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë¨¼ì € ëª¨ë‘ í‘œì‹œ
for message in st.session_state.messages:
    avatar = "ğŸ§‘â€ğŸ“" if message["role"] == "user" else "ğŸ¤–"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])


# 3. pending_input ë˜ëŠ” ìƒˆ ì‚¬ìš©ì ì…ë ¥ í™•ì¸
pending_input = st.session_state.conversation_state.get("pending_input")
user_input = st.chat_input("ìˆ˜í•™ ê°œë…ì„ ì…ë ¥í•˜ì„¸ìš”...")

# 4. ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì¡´ì¬í•˜ë©´ ë¡œì§ ì‹¤í–‰
if pending_input or user_input:
    
    input_to_process = ""
    run_logic = False 
    
    if pending_input:
        input_to_process = pending_input
        log_debug(f"Processing pending input: {input_to_process}")
        st.session_state.conversation_state.pop("pending_input")
        run_logic = True
        
    elif user_input:
        input_to_process = user_input
        st.session_state.messages.append({"role": "user", "content": user_input})
        run_logic = True
        
    # 5. AI íŠœí„° ì‘ë‹µ ìƒì„± (ê³µí†µ ë¡œì§)
    if run_logic:
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            message_placeholder = st.empty()
            full_response_content = ""
            new_state = get_initial_state()

            try:
                current_state = st.session_state.conversation_state
                log_debug(f"Calling master function: process_turn (Input: '{input_to_process}')")
                
                result_data = process_turn(input_to_process, current_state)
                
                explanation_stream = result_data.get("explanation_stream")
                response_text = result_data.get("response_text")
                new_state = result_data.get("new_state", get_initial_state())

                # ìŠ¤íŠ¸ë¦¬ë° ë˜ëŠ” í…ìŠ¤íŠ¸ ì¶œë ¥
                if explanation_stream:
                    # ìŠ¤íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ write_streamìœ¼ë¡œ ì¶œë ¥
                    full_response_content = message_placeholder.write_stream(explanation_stream)
                elif response_text:
                    # í…ìŠ¤íŠ¸ ì‘ë‹µ(ì§„ë‹¨ ì§ˆë¬¸, ì˜¤ë¥˜ ë“±)ì€ markdownìœ¼ë¡œ ì¶œë ¥
                    full_response_content = response_text
                    message_placeholder.markdown(full_response_content)
                else:
                    full_response_content = "ì˜¤ë¥˜: íŠœí„°ê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                    message_placeholder.error(full_response_content)

                st.session_state.conversation_state = new_state

            except Exception as e:
                full_response_content = f"ì£„ì†¡í•©ë‹ˆë‹¤, ì•± ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                log_debug(f"Error during response generation: {e}")
                message_placeholder.error(full_response_content)
                st.session_state.conversation_state = get_initial_state()

        # AI ì‘ë‹µ(ìµœì¢… í…ìŠ¤íŠ¸)ì„ ê¸°ë¡ì— ì¶”ê°€
        if full_response_content:
             st.session_state.messages.append({"role": "assistant", "content": full_response_content})

    # 6. rerun 
    st.rerun()

st.divider()
st.subheader("ğŸ“ í•™ìŠµ ê²½ë¡œ")
path_container = st.container()
with path_container:
    st.info("ê°œë…ì„ ì§ˆë¬¸í•˜ë©´ ì—¬ê¸°ì— í•™ìŠµ ê²½ë¡œê°€ í‘œì‹œë©ë‹ˆë‹¤.")