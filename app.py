import streamlit as st
import importlib
import sys
import os
import re
import json
from streamlit_agraph import agraph, Node, Edge, Config
from langchain_neo4j import Neo4jGraph
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

DEBUG_MODE = True # Trueë¡œ ì„¤ì •í•˜ë©´ ìƒì„¸ ë¡œê·¸ ì¶œë ¥

def log_debug(message: str):
    """ë””ë²„ê·¸ ëª¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if DEBUG_MODE:
        print(f"ğŸ› DEBUG: {message}")

scripts_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "scripts")
if scripts_path not in sys.path:
    sys.path.append(scripts_path)

try:
    tutor_module = importlib.import_module("06_tutor_rag")
    process_turn = tutor_module.process_turn
    get_initial_state = tutor_module.get_initial_state
except ImportError as e:
    st.error(f"íŠœí„° ë¡œì§ ìŠ¤í¬ë¦½íŠ¸(06_tutor_rag.py)ë¥¼ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="AI ìˆ˜í•™ íŠœí„°", page_icon="ğŸ“š",
    layout="wide", initial_sidebar_state="expanded"
)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ“Š ë‚˜ì˜ í•™ìŠµ í˜„í™©")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (get_initial_state í˜¸ì¶œ ì‹œ í”„ë¡œí•„ ë¡œë“œë¨)
    if "conversation_state" not in st.session_state:
        st.session_state.conversation_state = get_initial_state()

    current_state = st.session_state.conversation_state
    
    # JSONì—ì„œ listë¡œ ë¡œë“œëœ explained_concepts
    mastered_concepts_list = current_state.get("explained_concepts", []) 
    explanation_counts = current_state.get("explanation_count", {})

    # (ìˆ˜ì •) listì˜ ê¸¸ì´ë¡œ í•™ìŠµ ì™„ë£Œ ê°œìˆ˜ í‘œì‹œ
    st.metric("ğŸ“ í•™ìŠµ ì™„ë£Œ ê°œë…", f"{len(mastered_concepts_list)} ê°œ")

    # ì„¤ëª… íšŸìˆ˜ê°€ 2ë²ˆ ì´ìƒì¸ ê°œë…ì„ ì·¨ì•½ ê°œë…ìœ¼ë¡œ ê°„ì£¼
    weak_concepts_list = [
        name for name, count in explanation_counts.items() 
        if count >= 2 and name in mastered_concepts_list
    ]
    
    st.subheader("ğŸ¯ ë³µìŠµ ì¶”ì²œ ê°œë…")
    if weak_concepts_list:
        # (ìˆ˜ì •) ì„¤ëª… íšŸìˆ˜ë„ í•¨ê»˜ í‘œì‹œ
        for concept in weak_concepts_list:
            st.warning(f"- {concept} (ì„¤ëª… {explanation_counts.get(concept, 0)}íšŒ)")
    else:
        st.success("ğŸ‰ ëª¨ë“  ê°œë…ì„ ì˜ ì´í•´í•˜ê³  ìˆì–´ìš”!")
        
    st.divider()
    
    if st.button("ğŸ”„ í•™ìŠµ ê¸°ë¡ ì´ˆê¸°í™”"):
        try:
            profile_path = os.path.join("data", "user_profile.json")
            if os.path.exists(profile_path):
                os.remove(profile_path)
                st.toast("í”„ë¡œí•„ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"í”„ë¡œí•„ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
            
        st.session_state.conversation_state = get_initial_state() # ìƒˆ í”„ë¡œí•„ ë¡œë“œ (ë¹ˆ ìƒíƒœ)
        st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í•™ìŠµ ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."}]
        st.rerun()

# ë©”ì¸ í™”ë©´
st.title("ğŸ“š ìˆ˜í¬ìë¥¼ ìœ„í•œ AI ìˆ˜í•™ íŠœí„°")
st.caption("ê°œë…ì˜ ì„ ìˆ˜ ì§€ì‹ì„ í™•ì¸í•˜ë©° ì°¨ê·¼ì°¨ê·¼ í•™ìŠµí•´ìš”!")

# ì±„íŒ… ê¸°ëŠ¥ í•µì‹¬ ë¡œì§

# 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ìˆ˜í•™ ê°œë…ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."}]


# 2. ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë¨¼ì € ëª¨ë‘ í‘œì‹œ
for message in st.session_state.messages:
    avatar = "ğŸ§‘â€ğŸ“" if message["role"] == "user" else "ğŸ¤–"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])


# 3. pending_input ë˜ëŠ” ìƒˆ ì‚¬ìš©ì ì…ë ¥ í™•ì¸
pending_input = st.session_state.conversation_state.get("pending_input")
user_input = st.chat_input("ìˆ˜í•™ ê°œë…ì„ ì…ë ¥í•˜ì„¸ìš”...")

# 4. ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì¡´ì¬í•˜ë©´ ë¡œì§ ì‹¤í–‰
if pending_input or user_input:
    
    input_to_process = ""
    run_logic = False 
    
    if pending_input:
        input_to_process = pending_input
        log_debug(f"Processing pending input: {input_to_process}")
        st.session_state.conversation_state.pop("pending_input")
        run_logic = True
        
    elif user_input:
        input_to_process = user_input
        st.session_state.messages.append({"role": "user", "content": user_input})
        run_logic = True
        
    # 5. AI íŠœí„° ì‘ë‹µ ìƒì„± (ê³µí†µ ë¡œì§)
    if run_logic:
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            message_placeholder = st.empty()
            full_response_content = ""
            new_state = get_initial_state()

            try:
                current_state = st.session_state.conversation_state
                log_debug(f"Calling master function: process_turn (Input: '{input_to_process}')")
                
                result_data = process_turn(input_to_process, current_state)
                
                explanation_stream = result_data.get("explanation_stream")
                response_text = result_data.get("response_text")
                new_state = result_data.get("new_state", get_initial_state())

                # ìŠ¤íŠ¸ë¦¬ë° ë˜ëŠ” í…ìŠ¤íŠ¸ ì¶œë ¥
                if explanation_stream:
                    # ìŠ¤íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ write_streamìœ¼ë¡œ ì¶œë ¥
                    full_response_content = message_placeholder.write_stream(explanation_stream)
                elif response_text:
                    # í…ìŠ¤íŠ¸ ì‘ë‹µ(ì§„ë‹¨ ì§ˆë¬¸, ì˜¤ë¥˜ ë“±)ì€ markdownìœ¼ë¡œ ì¶œë ¥
                    full_response_content = response_text
                    message_placeholder.markdown(full_response_content)
                else:
                    full_response_content = "ì˜¤ë¥˜: íŠœí„°ê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                    message_placeholder.error(full_response_content)

                st.session_state.conversation_state = new_state

            except Exception as e:
                full_response_content = f"ì£„ì†¡í•©ë‹ˆë‹¤, ì•± ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                log_debug(f"Error during response generation: {e}")
                message_placeholder.error(full_response_content)
                st.session_state.conversation_state = get_initial_state()

        # AI ì‘ë‹µ(ìµœì¢… í…ìŠ¤íŠ¸)ì„ ê¸°ë¡ì— ì¶”ê°€
        if full_response_content:
             st.session_state.messages.append({"role": "assistant", "content": full_response_content})

    # 6. rerun 
    st.rerun()


#í•™ìŠµê²½ë¡œ ì‹œê°í™”

st.divider()
st.subheader("ğŸ“ í•™ìŠµ ê²½ë¡œ")
path_container = st.container(height=300) 

with path_container:
    # ì„¸ì…˜ ìƒíƒœì—ì„œ ì‹œê°í™” ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    current_state = st.session_state.conversation_state
    path_data = current_state.get("learning_path")
    # (ìˆ˜ì •) setì´ ì•„ë‹Œ list/tupleì¸ì§€ í™•ì¸ (JSONì—ì„œ ë¡œë“œëœ ìƒíƒœ)
    learned_concepts_iterable = current_state.get("explained_concepts", [])
    learned_concepts = set(learned_concepts_iterable) # setìœ¼ë¡œ ë³€í™˜
    current_goal = current_state.get("primary_goal_concept")

    if path_data and path_data.get("nodes"):
        nodes = []
        edges = []
        
        node_ids = set() # ì¤‘ë³µ ë…¸ë“œ ë°©ì§€
        
        # 1. ë…¸ë“œ ê°ì²´ ìƒì„± ë° ìŠ¤íƒ€ì¼ ì ìš©
        for n in path_data.get("nodes", []):
            node_id = n.get("id")
            if node_id not in node_ids:
                node_ids.add(node_id)
                
                # í•™ìŠµ ìƒíƒœì— ë”°ë¼ ë…¸ë“œ ìƒ‰ìƒ ë³€ê²½
                if node_id == current_goal:
                    color = "#FFD700" # ë…¸ë€ìƒ‰ (í˜„ì¬ ëª©í‘œ)
                    size = 20
                elif node_id in learned_concepts:
                    color = "#90EE90" # ì—°ë‘ìƒ‰ (í•™ìŠµ ì™„ë£Œ)
                    size = 15
                else:
                    color = "#D3D3D3" # íšŒìƒ‰ (ë¯¸í•™ìŠµ)
                    size = 15
                    
                nodes.append(Node(id=node_id, 
                                  label=n.get("label", node_id), 
                                  color=color,
                                  size=size))

        # 2. ì—£ì§€ ê°ì²´ ìƒì„±
        for e in path_data.get("edges", []):
            edges.append(Edge(source=e.get("source"), 
                              target=e.get("target"),
                              label=e.get("label", ""),
                              color="#D3D3D3")) # ì—£ì§€ ìƒ‰ìƒ

        # 3. ê·¸ë˜í”„ ì„¤ì • (ë¬¼ë¦¬ ì—”ì§„ ë¹„í™œì„±í™”)
        config = Config(width="100%",
                        height=280,
                        directed=True, 
                        physics=False, # (ì¤‘ìš”) ë¬¼ë¦¬ íš¨ê³¼ ë„ê¸°
                        hierarchical=True, # (ì¤‘ìš”) ê³„ì¸µ êµ¬ì¡°ë¡œ í‘œì‹œ
                        layout={"hierarchical": {"direction": "LR"}}, # ì¢Œ->ìš° ë°©í–¥
                        )

        agraph(nodes=nodes, edges=edges, config=config)

    else:
        st.info("ê°œë…ì„ ì§ˆë¬¸í•˜ë©´ ì—¬ê¸°ì— í•™ìŠµ ê²½ë¡œê°€ í‘œì‹œë©ë‹ˆë‹¤.")